{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: tritonclient[all]\r\n"
     ]
    }
   ],
   "source": [
    "!bash -c python -m pip install tritonclient[all]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import tritonclient.http as httpclient\n",
    "import numpy as np\n",
    "from torchvision import datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def get_triton_client(protocol):\n",
    "\tlogging.info(\"Retrieving triton client\")\n",
    "\ttriton_dns = \"localhost\"\n",
    "\tif not triton_dns:\n",
    "\t\traise Exception(f\"Cannot find triton_dns\")\n",
    "\tif protocol == \"grpc\":\n",
    "\t\ttriton_uri = f\"{triton_dns}:8001\"\n",
    "\telse:\n",
    "\t\ttriton_uri = f\"{triton_dns}:8000\"\n",
    "\n",
    "\tlogging.info(f\"Using protocol={protocol} triton_dns={triton_uri}\")\n",
    "\n",
    "\tlogging.info(f\"Connecting to {triton_uri}\")\n",
    "\n",
    "\t# Specify large enough concurrency to handle the\n",
    "\t# the number of requests.\n",
    "\tconcurrency = 20\n",
    "\ttriton_client = httpclient.InferenceServerClient(\n",
    "\t\turl=triton_uri, concurrency=concurrency\n",
    "\t)\n",
    "\treturn triton_client"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model_name = \"mnist_classifier\"\n",
    "model_version = \"1\"\n",
    "\n",
    "protocol = \"http\"\n",
    "triton_client = get_triton_client(protocol)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "batch = [np.random.rand(1, 28, 28).astype(\"float32\") for _ in range(10)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "input_name = \"input\"\n",
    "output_name = \"output\"\n",
    "dtype=\"FP32\"\n",
    "classes = 10\n",
    "\n",
    "batched_image_data = np.stack(batch, axis=0)\n",
    "inputs = [httpclient.InferInput(input_name, batched_image_data.shape, dtype)]\n",
    "inputs[0].set_data_from_numpy(batched_image_data)\n",
    "outputs = [httpclient.InferRequestedOutput(output_name, class_count=classes)]\n",
    "response = triton_client.infer(\n",
    "\tmodel_name,\n",
    "\tinputs,\n",
    "\trequest_id=\"0\",\n",
    "\tmodel_version=model_version,\n",
    "\toutputs=outputs,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': '0',\n 'model_name': 'mnist_classifier',\n 'model_version': '1',\n 'outputs': [{'name': 'output',\n   'datatype': 'BYTES',\n   'shape': [10, 10],\n   'parameters': {'binary_data_size': 2209}}]}"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = response.get_response()\n",
    "r"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[b'2.812821:2:Pullover', b'2.759900:8:Bag', b'2.749728:6:Shirt',\n        b'1.851528:4:Coat', b'1.432543:0:T-shirt/top',\n        b'-0.364798:5:Sandal', b'-0.570288:3:Dress',\n        b'-1.213886:9:Ankle boot', b'-3.550432:1:Trouser',\n        b'-4.199965:7:Sneaker'],\n       [b'2.732077:8:Bag', b'2.630997:6:Shirt', b'2.358886:2:Pullover',\n        b'1.651615:4:Coat', b'1.338836:0:T-shirt/top',\n        b'-0.317795:5:Sandal', b'-0.349168:3:Dress',\n        b'-1.143678:9:Ankle boot', b'-3.352515:1:Trouser',\n        b'-3.939103:7:Sneaker'],\n       [b'2.632139:6:Shirt', b'2.507267:8:Bag', b'2.492306:2:Pullover',\n        b'1.664160:4:Coat', b'1.505023:0:T-shirt/top',\n        b'-0.164413:5:Sandal', b'-0.605954:3:Dress',\n        b'-0.899673:9:Ankle boot', b'-3.433556:1:Trouser',\n        b'-3.884909:7:Sneaker'],\n       [b'2.765271:8:Bag', b'2.387483:6:Shirt', b'2.213422:2:Pullover',\n        b'1.350260:4:Coat', b'1.322876:0:T-shirt/top',\n        b'-0.024314:5:Sandal', b'-0.578251:3:Dress',\n        b'-0.695463:9:Ankle boot', b'-3.503358:7:Sneaker',\n        b'-3.635479:1:Trouser'],\n       [b'3.088771:6:Shirt', b'2.898730:2:Pullover', b'2.710687:8:Bag',\n        b'2.003471:4:Coat', b'1.744775:0:T-shirt/top',\n        b'-0.138064:3:Dress', b'-0.854364:5:Sandal',\n        b'-1.741508:9:Ankle boot', b'-3.634803:1:Trouser',\n        b'-4.470034:7:Sneaker'],\n       [b'3.633785:8:Bag', b'2.555318:6:Shirt', b'2.315772:2:Pullover',\n        b'1.738319:4:Coat', b'1.078637:0:T-shirt/top',\n        b'-0.046950:5:Sandal', b'-0.518682:3:Dress',\n        b'-0.602480:9:Ankle boot', b'-3.947101:7:Sneaker',\n        b'-4.219763:1:Trouser'],\n       [b'2.776509:8:Bag', b'2.519929:6:Shirt', b'2.386015:2:Pullover',\n        b'1.508403:4:Coat', b'1.425598:0:T-shirt/top',\n        b'-0.073529:5:Sandal', b'-0.349019:3:Dress',\n        b'-0.727452:9:Ankle boot', b'-3.835215:1:Trouser',\n        b'-3.983328:7:Sneaker'],\n       [b'3.639971:8:Bag', b'2.485554:2:Pullover', b'2.362427:6:Shirt',\n        b'1.692940:4:Coat', b'0.749997:0:T-shirt/top',\n        b'0.370200:5:Sandal', b'-0.434786:9:Ankle boot',\n        b'-0.993693:3:Dress', b'-3.453621:7:Sneaker',\n        b'-4.528610:1:Trouser'],\n       [b'2.915100:8:Bag', b'2.764524:2:Pullover', b'2.732590:6:Shirt',\n        b'2.130240:4:Coat', b'1.117160:0:T-shirt/top',\n        b'-0.369184:5:Sandal', b'-0.520168:3:Dress',\n        b'-1.774678:9:Ankle boot', b'-3.488763:1:Trouser',\n        b'-4.021248:7:Sneaker'],\n       [b'3.102806:6:Shirt', b'2.953235:8:Bag', b'2.924389:2:Pullover',\n        b'2.118210:4:Coat', b'1.792966:0:T-shirt/top',\n        b'-0.294305:3:Dress', b'-0.702816:5:Sandal',\n        b'-1.663431:9:Ankle boot', b'-3.846899:1:Trouser',\n        b'-4.675126:7:Sneaker']], dtype=object)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.as_numpy(\"output\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_model_metadata_config(model_name, model_version, triton_client, protocol):\n",
    "    # Make sure the model matches our requirements, and get some\n",
    "    # properties of the model that we need for preprocessing\n",
    "    logging.info(\n",
    "        f\"Retrieve model info of model {model_name} and version {model_version}\"\n",
    "    )\n",
    "    model_metadata = triton_client.get_model_metadata(\n",
    "        model_name=model_name, model_version=model_version\n",
    "    )\n",
    "    logging.info(f\"Found: {model_metadata}\")\n",
    "\n",
    "    logging.info(\n",
    "        f\"Retrieve model config of model {model_name} and version {model_version}\"\n",
    "    )\n",
    "    model_config = triton_client.get_model_config(\n",
    "        model_name=model_name, model_version=model_version\n",
    "    )\n",
    "    logging.info(f\"Found: {model_config}\")\n",
    "\n",
    "    # if protocol.lower() == \"grpc\":\n",
    "    #     model_config = model_config.config\n",
    "    # else:\n",
    "    #     model_metadata, model_config = convert_http_metadata_config(\n",
    "    #         model_metadata, model_config\n",
    "    #     )\n",
    "\n",
    "    return model_metadata, model_config"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
